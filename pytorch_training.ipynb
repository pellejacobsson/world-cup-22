{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pejacobs\\Miniconda3\\envs\\ds-torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FootballDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "\n",
    "\n",
    "class FootballDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, national_filename, league_filename, feature_cols=None):\n",
    "        super().__init__()\n",
    "        self.national_filename = national_filename\n",
    "        self.league_filename = league_filename\n",
    "        self.feature_cols = feature_cols\n",
    "        self.n_classes = 6\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        df1 = pd.read_parquet(self.national_filename)\n",
    "        df2 = pd.read_parquet(self.league_filename)\n",
    "        df = pd.concat([df1, df2])\n",
    "        if self.feature_cols is not None:\n",
    "            x = df[self.feature_cols].values\n",
    "        else:\n",
    "            x = df.drop(columns=['team1', 'team2', 'team1_score', 'team1_home']).values\n",
    "        y = df['team1_score'].values\n",
    "        y[y > 5] = 5\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_val = scaler.transform(x_val)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        self.ds_train = FootballDataset(torch.Tensor(x_train), torch.LongTensor(y_train))\n",
    "        self.ds_val = FootballDataset(torch.Tensor(x_val), torch.LongTensor(y_val))\n",
    "        self.ds_test = FootballDataset(torch.Tensor(x_test), torch.LongTensor(y_test))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, batch_size=64)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=64)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FootballNN(pl.LightningModule):\n",
    "    def __init__(self, n_input, n_classes, learning_rate=1e-3,\n",
    "        use_dropout=False, use_batch_norm=True, activation='tanh'):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        def block(n_in, n_out, use_dropout, use_batch_norm, activation):\n",
    "            layers = [nn.Linear(n_in, n_out)]\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(n_out))\n",
    "            if activation == 'tanh':\n",
    "                layers.append(nn.Tanh())\n",
    "            else:\n",
    "                layers.append(nn.ReLU())\n",
    "            if use_dropout:\n",
    "                layers.append(nn.Dropout(0.2))\n",
    "            return layers\n",
    "\n",
    "        do = self.hparams.use_dropout\n",
    "        bn = self.hparams.use_batch_norm\n",
    "        act = self.hparams.activation\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(self.hparams.n_input, 50, do, bn, act),\n",
    "            *block(50, 100, do, bn, act),\n",
    "            *block(100, 100, do, bn, act),\n",
    "            *block(100, 50, do, bn, act),\n",
    "            *block(50, 10, do, bn, act),\n",
    "            nn.Linear(10, self.hparams.n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "         return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['overall', 'potential', 'skill_moves', 'attacking_finishing', \n",
    "          'skill_long_passing', 'movement_sprint_speed', 'movement_agility', \n",
    "          'value_eur', 'wage_eur', 'attacking_finishing', 'power_stamina']\n",
    "x_cols = [s + a for s in x_cols  for a in ['_min', '_mean', '_max']]\n",
    "x_cols = x_cols + ['goalkeeping_positioning_max', 'goalkeeping_reflexes_max']\n",
    "x_cols = [t + s for t in ['team1_', 'team2_'] for s in x_cols]\n",
    "y_cols = ['team1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = FootballDataModule('national_games.parquet', 'league_games.parquet', feature_cols=x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 70\n",
    "model = FootballNN(n_input, dl.n_classes, use_dropout=False, use_batch_norm=True, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pejacobs\\Miniconda3\\envs\\ds-torch\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:89: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 25.0 K\n",
      "-------------------------------------\n",
      "25.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.0 K    Total params\n",
      "0.100     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pejacobs\\Miniconda3\\envs\\ds-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pejacobs\\Miniconda3\\envs\\ds-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\pejacobs\\Miniconda3\\envs\\ds-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1892: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 2/2 [00:00<00:00, 42.51it/s, loss=5.56e-05, v_num=22] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 2/2 [00:00<00:00, 37.30it/s, loss=5.56e-05, v_num=22]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pejacobs\\Miniconda3\\envs\\ds-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 34/34 [00:00<00:00, 336.62it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.7324435710906982\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.7324435710906982}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ds-torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06ceebebc1983e49b124ba5abc54ce4e43dd3eff1bb54d450d5cac39ea42b747"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
